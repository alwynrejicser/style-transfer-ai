"""
Style Transfer AI - Perfect Stylometry Analyzer
==============================================
Ultimate stylometry analysis system combining the best of all features:
- Dual-mode operation (Local Ollama + OpenAI API)
- Flexible API key management with validation
- Comprehensive 15-point stylometric analysis framework
- Individual file analysis + consolidated profiling
- Professional JSON output with metadata
- Robust error handling and user experience

Features:
âœ“ Local Privacy: Use Ollama models for confidential analysis
âœ“ Cloud Power: OpenAI GPT-3.5-turbo for advanced analysis  
âœ“ Flexible Keys: Use existing or enter custom API keys
âœ“ Deep Analysis: 15 stylometric dimensions with quantifiable metrics
âœ“ Multi-Sample: Analyze multiple files individually and collectively
âœ“ Production Ready: Comprehensive error handling and validation

Usage:
    python style_analyzer_simple.py

Author: Style Transfer AI Team
Version: 3.0 (Perfect Edition)
"""

import os
import json
import requests
from datetime import datetime

# Configuration
OLLAMA_BASE_URL = "http://localhost:11434"
AVAILABLE_MODELS = {
    "gpt-oss:20b": "GPT-OSS 20B (Advanced, Slower)",
    "gemma3:1b": "Gemma 3:1B (Fast, Efficient)",
}
OPENAI_API_KEY = "your-openai-api-key-here"  # Replace with your actual OpenAI API key

# Global variables
USE_LOCAL_MODEL = None
SELECTED_MODEL = None
USER_CHOSEN_API_KEY = None

def get_user_model_choice():
    """Ask user to choose between local Ollama models or OpenAI API."""
    print("Style Transfer AI - Perfect Stylometry Analyzer")
    print("=" * 60)
    print("Choose your analysis method:")
    print("1. Local Ollama - GPT-OSS 20B (Advanced, Comprehensive)")
    print("2. Local Ollama - Gemma 3:1B (Fast, Efficient)")
    print("3. OpenAI API - GPT-3.5-turbo (Cloud, Requires API key)")
    
    while True:
        choice = input("\nEnter your choice (1, 2, or 3): ").strip()
        if choice == "1":
            return True, "gpt-oss:20b"  # Use local model with GPT-OSS
        elif choice == "2":
            return True, "gemma3:1b"    # Use local model with Gemma
        elif choice == "3":
            return False, None          # Use OpenAI API
        else:
            print("Please enter 1, 2, or 3")

def get_api_key():
    """Get API key from user with validation and existing key detection."""
    global OPENAI_API_KEY
    
    # Check if there's an existing API key in the code
    if OPENAI_API_KEY and len(OPENAI_API_KEY) > 20:
        masked_key = f"{OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-10:]}"
        print(f"\nFound existing API key: {masked_key}")
        use_existing = input("Do you want to use this API key? (y/n): ").strip().lower()
        
        if use_existing == 'y':
            return OPENAI_API_KEY
    
    # Get new API key from user
    print("\nPlease enter your OpenAI API key:")
    print("(You can find this at: https://platform.openai.com/api-keys)")
    
    while True:
        try:
            api_key = input("API Key: ").strip()
            
            if not api_key:
                print("API key cannot be empty. Please try again.")
                continue
                
            if len(api_key) < 20:
                print("API key seems too short. Please check and try again.")
                continue
                
            return api_key
            
        except KeyboardInterrupt:
            print("\n\nSetup cancelled by user.")
            return None

def check_ollama_connection(model_name):
    """Check if Ollama server is running and specified model is available."""
    try:
        # Check if Ollama server is running
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [model.get('name', '') for model in models]
            
            if model_name in model_names:
                return True, f"Ollama server running with {model_name} model available"
            else:
                return False, f"Model {model_name} not found. Available models: {model_names}"
        else:
            return False, f"Ollama server responded with status {response.status_code}"
    except requests.exceptions.ConnectionError:
        return False, "Cannot connect to Ollama server. Please run 'ollama serve'"
    except Exception as e:
        return False, f"Error checking Ollama: {e}"

def setup_openai_client(api_key=None):
    """Initialize OpenAI client with provided API key."""
    global USER_CHOSEN_API_KEY
    
    try:
        from openai import OpenAI
        
        # Use provided key or get from user
        if not api_key:
            api_key = get_api_key()
        
        if not api_key:
            return None, "No API key provided"
        
        # Store the chosen API key for later use
        USER_CHOSEN_API_KEY = api_key
        
        client = OpenAI(api_key=api_key)
        return client, f"OpenAI client initialized successfully with key: {api_key[:10]}...{api_key[-10:]}"
    except ImportError:
        return None, "OpenAI library not installed. Run: pip install openai"
    except Exception as e:
        return None, f"Error initializing OpenAI client: {e}"

def read_text_file(file_path):
    """
    Reads text content from a file.
    
    Args:
        file_path (str): Path to the text file
        
    Returns:
        str: File content or error message
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            return content
    except FileNotFoundError:
        return f"Error: File '{file_path}' not found"
    except Exception as e:
        return f"Error reading file: {e}"

def create_comprehensive_prompt(text_to_analyze):
    """Create the comprehensive 15-point stylometry analysis prompt."""
    return f"""
Perform a comprehensive stylometry analysis of the following text for creating a detailed writing style profile. Analyze and provide specific, quantifiable insights on:

*LINGUISTIC PATTERNS:*
1. Sentence Structure: Average length, complexity patterns (simple/compound/complex ratios), preferred sentence types
2. Clause Patterns: Subordinate clause usage, coordination vs subordination preferences  
3. Punctuation Style: Comma usage patterns, semicolon frequency, dash/parentheses preferences

*LEXICAL CHARACTERISTICS:*
4. Vocabulary Level: Formal vs informal ratio, technical term usage, abstract vs concrete word preferences
5. Word Choice Patterns: Synonyms preferences, adjective/adverb density, specific vs general terms
6. Frequency Patterns: Most used transition words, preferred conjunctions, filler words

*STYLISTIC MARKERS:*
7. Tone Indicators: Confidence level, emotional markers, certainty expressions
8. Narrative Voice: Person preference (1st/2nd/3rd), active vs passive voice ratio
9. Rhetorical Devices: Metaphor usage, repetition patterns, parallel structure frequency

*STRUCTURAL PREFERENCES:*
10. Paragraph Organization: Length preferences, topic transition methods
11. Flow Patterns: How ideas are connected, logical progression style
12. Emphasis Techniques: How important points are highlighted

*PERSONAL MARKERS:*
13. Idiomatic Expressions: Unique phrases or expressions used
14. Cultural References: Types of references made
15. Formality Adaptability: Range between formal and casual registers

Provide your analysis as a structured JSON-like format with specific examples and percentages where possible. Include quantitative metrics like word count, sentence count, and paragraph count.

Text to analyze:
{text_to_analyze}
"""

def analyze_style(text_to_analyze, use_local=True, model_name="gpt-oss:20b"):
    """
    Performs comprehensive stylometry analysis using either local Ollama or OpenAI API.
    
    Args:
        text_to_analyze (str): The text to be analyzed
        use_local (bool): Whether to use local Ollama model or OpenAI API
        model_name (str): The specific model to use (for local models)
        
    Returns:
        str: Structured stylometric analysis for style profiling
    """
    prompt = create_comprehensive_prompt(text_to_analyze)
    
    if use_local:
        # Use local Ollama model
        try:
            print(f"Sending request to local Ollama model ({model_name})...")
            
            payload = {
                "model": model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "top_p": 0.9,
                    "top_k": 40,
                    "num_predict": 2000 if "gpt-oss" in model_name else 1000,  # Adjust for model size
                    "stop": ["Human:", "Assistant:"]
                }
            }
            
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/generate",
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                print("âœ“ Analysis completed successfully!")
                return result.get('response', 'No response received')
            else:
                return f"Ollama Error: HTTP {response.status_code} - {response.text}"
                
        except requests.exceptions.Timeout:
            return "Timeout Error: Analysis took too long. Try with shorter text or use OpenAI API."
        except Exception as e:
            return f"Ollama Error: {e}"
    
    else:
        # Use OpenAI API
        try:
            from openai import OpenAI
            global USER_CHOSEN_API_KEY
            
            if not USER_CHOSEN_API_KEY:
                return "OpenAI Error: No API key available. Please restart and set up API key."
            
            openai_client = OpenAI(api_key=USER_CHOSEN_API_KEY)
        except ImportError:
            return "OpenAI Error: OpenAI library not installed. Run: pip install openai"
        except Exception as e:
            return f"OpenAI Error: {e}"
        
        print("Sending request to OpenAI GPT-3.5-turbo model...")
        
        try:
            response = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            print("âœ“ Analysis completed successfully!")
            return response.choices[0].message.content
        except Exception as e:
            return f"OpenAI API Error: {e}"

def create_style_profile(file_paths, use_local=True, model_name="gpt-oss:20b"):
    """
    Creates a comprehensive style profile from multiple text samples.
    
    Args:
        file_paths (list): List of file paths containing user's writing samples
        use_local (bool): Whether to use local Ollama model or OpenAI API
        model_name (str): The specific model to use (for local models)
        
    Returns:
        dict: Consolidated style profile
    """
    all_analyses = []
    combined_text = ""
    
    print(f"âœ“ Found {len(file_paths)} text sample(s) to analyze")
    
    for file_path in file_paths:
        file_content = read_text_file(file_path)
        
        if "Error" not in file_content:
            print(f"\n--- Analyzing File: {os.path.basename(file_path)} ---")
            
            # Individual file analysis
            analysis_result = analyze_style(file_content, use_local, model_name)
            all_analyses.append({
                'file': os.path.basename(file_path),
                'analysis': analysis_result,
                'word_count': len(file_content.split()),
                'char_count': len(file_content),
                'paragraph_count': file_content.count('\n\n') + 1
            })
            
            combined_text += file_content + "\n\n"
            print(f"âœ“ Analysis complete for {os.path.basename(file_path)}")
        else:
            print(f"âŒ Error reading {file_path}: {file_content}")
    
    # Comprehensive analysis of all texts combined
    comprehensive_analysis = ""
    if combined_text:
        print("\n--- Creating Consolidated Style Profile ---")
        comprehensive_analysis = analyze_style(combined_text, use_local, model_name)
        
        if "Error" in comprehensive_analysis:
            print("âš ï¸  Consolidated analysis failed, using summary of individual analyses")
            comprehensive_analysis = create_fallback_summary(all_analyses)
    
    # Create the style profile
    model_used = f"ollama-{model_name}" if use_local else "openai-gpt-3.5-turbo"
    
    style_profile = {
        'metadata': {
            'analysis_timestamp': datetime.now().isoformat(),
            'model_used': model_used,
            'total_word_count': len(combined_text.split()) if combined_text else 0,
            'total_char_count': len(combined_text) if combined_text else 0,
            'sample_count': len(all_analyses),
            'files_analyzed': [analysis['file'] for analysis in all_analyses]
        },
        'individual_analyses': all_analyses,
        'comprehensive_profile': comprehensive_analysis,
        'profile_created': True,
        'version': '3.0'
    }
    
    return style_profile

def create_fallback_summary(analyses):
    """Create a fallback summary when consolidated analysis fails."""
    total_words = sum(a['word_count'] for a in analyses)
    files = [a['file'] for a in analyses]
    
    return f"""
FALLBACK SUMMARY - Individual Analyses Completed Successfully
============================================================
Files analyzed: {', '.join(files)}
Total words processed: {total_words}
Analysis method: Individual file processing (consolidated analysis unavailable)

Each file was successfully analyzed with the full 15-point stylometry framework.
The individual analyses contain comprehensive style profiles for each text sample.
This fallback summary indicates successful processing despite consolidation limitations.
"""

def save_style_profile(style_profile, profile_path="user_style_profile.json"):
    """
    Saves the style profile to a JSON file for later use.
    
    Args:
        style_profile (dict): The style profile data
        profile_path (str): Path to save the profile
        
    Returns:
        bool: Success status
    """
    try:
        with open(profile_path, 'w', encoding='utf-8') as file:
            json.dump(style_profile, file, indent=2, ensure_ascii=False)
        print(f"\nâœ“ Style profile saved to: {profile_path}")
        return True
    except Exception as e:
        print(f"âŒ Error saving profile: {e}")
        return False

def display_results(style_profile):
    """Display comprehensive results in a professional format."""
    print("\n" + "="*60)
    print("COMPREHENSIVE STYLE PROFILE CREATED")
    print("="*60)
    
    # Display metadata
    metadata = style_profile['metadata']
    print("Profile Statistics:")
    print(f"- Samples analyzed: {metadata['sample_count']}")
    print(f"- Total words: {metadata['total_word_count']}")
    print(f"- Model used: {metadata['model_used']}")
    print(f"- Analysis timestamp: {metadata['analysis_timestamp']}")
    print(f"- Files: {', '.join(metadata['files_analyzed'])}")
    
    print(f"\nâœ“ Your style profile is ready for text generation!")

def main():
    """Main execution function."""
    print("Style Transfer AI - Perfect Stylometry Analyzer")
    print("=" * 60)
    
    # Get user's model choice
    use_local, selected_model = get_user_model_choice()
    
    # Validate setup based on choice
    if use_local:
        model_display = AVAILABLE_MODELS.get(selected_model, selected_model)
        print(f"\nðŸ¤– Local Ollama Model Selected: {model_display}")
        print("=" * 50)
        
        # Check Ollama connection and model availability
        is_connected, message = check_ollama_connection(selected_model)
        if not is_connected:
            print(f"âŒ Ollama Setup Error: {message}")
            print("\nTo fix this:")
            print("1. Make sure Ollama is installed")
            print("2. Run 'ollama serve' in a terminal")
            print(f"3. Ensure you have the model: ollama pull {selected_model}")
            exit(1)
        
        print(f"âœ“ {message}")
    else:
        print("\nðŸŒ OpenAI API Model Selected")
        print("=" * 40)
        
        # Get API key and check OpenAI setup
        try:
            openai_client, setup_message = setup_openai_client()
            if not openai_client:
                print(f"âŒ OpenAI Error: {setup_message}")
                exit(1)
            
            print(f"âœ“ {setup_message}")
        except KeyboardInterrupt:
            print("\n\nSetup cancelled by user.")
            exit(1)
        except Exception as e:
            print(f"âŒ Unexpected error: {e}")
            exit(1)
    
    # Define file paths for analysis
    file_paths = [
        "about_my_pet.txt",
        "about_my _pet_1.txt"
    ]
    
    print("\nCreating comprehensive style profile...")
    print("=" * 60)
    
    # Create comprehensive style profile
    if use_local:
        style_profile = create_style_profile(file_paths, use_local, selected_model)
    else:
        style_profile = create_style_profile(file_paths, use_local)
    
    if style_profile['profile_created']:
        # Save the profile
        save_style_profile(style_profile)
        
        # Display results
        display_results(style_profile)
        
    else:
        print("âŒ Failed to create style profile")
        print(f"Error: {style_profile.get('error', 'Unknown error')}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nðŸ‘‹ Analysis cancelled by user. Goodbye!")
    except Exception as e:
        print(f"\nâŒ Unexpected error occurred: {e}")
        print("Please check your setup and try again.")